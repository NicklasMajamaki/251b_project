{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtpRJtJ7jKmo"
      },
      "source": [
        "# CSE251B Project Milestone Starter File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir_VbBlRjKmq"
      },
      "source": [
        "## Step 1: Import Dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlOkUAyvjKmq",
        "outputId": "f8e8ec3d-4980-484b-bcee-6f6cad2010cb"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "from transformers import MambaModel, MambaConfig\n",
        "from typing import Optional, Tuple, Dict\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teyO4QBAjKms"
      },
      "source": [
        "## Step 2: Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTfrTwVJjKmt"
      },
      "source": [
        "#### You need to describe in your own words what the dataset is about, and use mathematical language and formulate your prediction task on the submitted PDF file for Question 1 Problem A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYEqPu-MjKmt"
      },
      "source": [
        "#### Here we are loading the dataset from the local directory. And answer Question 1 Problem B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmXptbI8jOP9",
        "outputId": "46d80681-f2e6-464e-d936-ba45544ad05d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_npz = np.load('/content/drive/My Drive/251B_data/train.npz')\n",
        "test_npz = np.load('/content/drive/My Drive/251B_data/test_input.npz')\n",
        "train_data = train_npz['data']\n",
        "test_data = test_npz['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfTjEsRojKmu",
        "outputId": "522e2df6-63cb-4a36-c758-6383cb0d63ec"
      },
      "outputs": [],
      "source": [
        "print(train_data.shape, test_data.shape)\n",
        "\n",
        "# Split once for later use\n",
        "X_train = train_data[..., :50, :]\n",
        "Y_train = train_data[:, 0, 50:, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsLmUjWLjKmw"
      },
      "outputs": [],
      "source": [
        "xy_in = train_data[:, :, :50, :2].reshape(-1, 2)\n",
        "# only find the x, y != 0\n",
        "xy_in_not_0 = xy_in[(xy_in[:, 0] != 0) & (xy_in[:, 1] != 0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAhF7O8GjKmx"
      },
      "source": [
        "#### Try to play around with dataset for training and testing, make exploratory analysis on the dataset for bonus points(up to 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf67FAN9jKmy"
      },
      "source": [
        "## Step 3: Setting up the Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVyUmmrtjKmy"
      },
      "source": [
        "### Example Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVxyqxiXjKmy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: shape (N, 50, 110, 6)\n",
        "        scale: normalization factor\n",
        "        augment: whether to apply random horizontal flipping\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx].copy()\n",
        "\n",
        "        # === Rotate so agent 0 has heading 0 at t=49 ===\n",
        "        ego_heading = scene[0, 49, 4]\n",
        "        cos_theta = np.cos(-ego_heading)\n",
        "        sin_theta = np.sin(-ego_heading)\n",
        "        R = np.array([[cos_theta, -sin_theta],\n",
        "                      [sin_theta,  cos_theta]], dtype=np.float32)\n",
        "\n",
        "        scene[..., 0:2] = scene[..., 0:2] @ R.T\n",
        "        scene[..., 2:4] = scene[..., 2:4] @ R.T\n",
        "        scene[..., 4] = scene[..., 4] - ego_heading\n",
        "\n",
        "        # === Get history and future ===\n",
        "        hist = scene[:, :50, :].copy()\n",
        "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)\n",
        "\n",
        "        # === Random horizontal flip (only during training) ===\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # === Translate to origin (agent 0 at t=49) ===\n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future = future - origin\n",
        "\n",
        "        # === Normalize by scale ===\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        return Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future,\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "\n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 50, 6) for test set with historical trajectory only\n",
        "        scale: Normalization factor\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx].copy()\n",
        "\n",
        "        # === Rotate so agent 0 has heading 0 at t=49 ===\n",
        "        ego_heading = scene[0, 49, 4]\n",
        "        cos_theta = np.cos(-ego_heading)\n",
        "        sin_theta = np.sin(-ego_heading)\n",
        "        R = np.array([[cos_theta, -sin_theta],\n",
        "                      [sin_theta,  cos_theta]], dtype=np.float32)\n",
        "\n",
        "        # Apply rotation (same as training: @ R.T)\n",
        "        scene[..., 0:2] = scene[..., 0:2] @ R.T\n",
        "        scene[..., 2:4] = scene[..., 2:4] @ R.T\n",
        "        scene[..., 4] = scene[..., 4] - ego_heading\n",
        "\n",
        "        # === Get history (only historical data available for test) ===\n",
        "        hist = scene.copy()  # (50, 50, 6)\n",
        "\n",
        "        # === Translate to origin (agent 0 at t=49) - SAME AS TRAINING ===\n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "\n",
        "        # === Normalize by scale ===\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        return Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "            rotation=torch.tensor(R, dtype=torch.float32)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpdUtssvjKmy"
      },
      "source": [
        "#### Answer Question related to Your Computational Platform and GPU for Question 2 Problem A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sORc8kt5jKmz",
        "outputId": "58f82678-b24c-4a8e-92d5-29ef3dc31b8e"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 10.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "#train_data_shuffled = np.random.permutation(train_data)\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "#train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=False)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP7kHO2KjKmz"
      },
      "source": [
        "#### Your Model for Question 2 Problem B (Include your model architecture pictures and also can use some mathmatical equations to explain your model in your report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfyXCo1ajKmz"
      },
      "source": [
        "#### This Model will be covered during Week 6 Lecture (If you don't understand it for now, don't worry, we will cover it in the lecture, or you can ask in the office hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQpGK8nmLsKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedSocialAttention(nn.Module):\n",
        "    def __init__(self, ego_dim, other_dim, radius=40.0, heads=8):\n",
        "        super().__init__()\n",
        "        self.radius = radius\n",
        "        self.heads = heads\n",
        "        self.head_dim = other_dim // heads\n",
        "\n",
        "        # Multi-head projections\n",
        "        self.q_proj = nn.Linear(ego_dim, other_dim)\n",
        "        self.k_proj = nn.Linear(other_dim + 5, other_dim)\n",
        "        self.v_proj = nn.Linear(other_dim + 5, other_dim)\n",
        "        self.out = nn.Linear(other_dim, other_dim)\n",
        "\n",
        "        # Learnable positional encoding for relative positions\n",
        "        self.pos_encoding = nn.Sequential(\n",
        "            nn.Linear(5, other_dim // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(other_dim // 4, other_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, ego_h, other_h, rel_pos, rel_vel):\n",
        "        \"\"\"\n",
        "        ego_h   : [B, emb]             (query from ego LSTM)\n",
        "        other_h : [B, A-1, emb]        (other-agent encodings)\n",
        "        rel_pos : [B, A-1, 3]          (dx, dy, dist)\n",
        "        rel_vel : [B, A-1, 2]          (dvx, dvy)\n",
        "        \"\"\"\n",
        "        B, N, _ = other_h.shape\n",
        "\n",
        "        distances = rel_pos[..., 2]\n",
        "        mask = distances <= self.radius\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            return torch.zeros_like(other_h[:, 0])\n",
        "\n",
        "        rel_features = torch.cat([rel_pos, rel_vel], dim=-1)\n",
        "\n",
        "        # Enhanced K, V with positional encoding\n",
        "        pos_enc = self.pos_encoding(rel_features)\n",
        "        kv_input = other_h + pos_enc\n",
        "\n",
        "        q = self.q_proj(ego_h).view(B, 1, self.heads, self.head_dim)\n",
        "        k = self.k_proj(torch.cat([kv_input, rel_features], dim=-1)).view(B, N, self.heads, self.head_dim)\n",
        "        v = self.v_proj(torch.cat([kv_input, rel_features], dim=-1)).view(B, N, self.heads, self.head_dim)\n",
        "\n",
        "        # Scaled dot-product attention with improved masking\n",
        "        attn = torch.einsum('bqhd,bnhd->bnhq', q, k) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # Distance-aware attention weighting\n",
        "        distance_weight = torch.exp(-distances / (self.radius / 3)).unsqueeze(-1).unsqueeze(-1)\n",
        "        attn = attn * distance_weight\n",
        "\n",
        "        attn = attn.masked_fill(~mask.unsqueeze(-1).unsqueeze(-1), -1e9)\n",
        "        attn = F.softmax(attn, dim=1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        ctx = torch.einsum('bnhq,bnhd->bqhd', attn, v).flatten(2)\n",
        "        return self.out(ctx.squeeze(1))\n",
        "\n",
        "class ImprovedLSTMParametricTrajectoryFeatures(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=9,\n",
        "                 emb_dim=128,\n",
        "                 hidden_dim=256,\n",
        "                 lstm_layers=2,\n",
        "                 degree=3,\n",
        "                 social_heads=8,\n",
        "                 radius=35.0,\n",
        "                 other_rnn_dim=256):\n",
        "        super().__init__()\n",
        "        self.degree = degree\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Enhanced ego network with bidirectional LSTM\n",
        "        self.emb = nn.Linear(input_dim, emb_dim)\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.ego_lstm = nn.LSTM(emb_dim, hidden_dim,\n",
        "                                batch_first=True, num_layers=lstm_layers,\n",
        "                                bidirectional=True, dropout=0.1)\n",
        "\n",
        "        # Project bidirectional output back to hidden_dim\n",
        "        self.ego_proj = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        # Enhanced other-agent encoder\n",
        "        self.other_emb = nn.Linear(input_dim, other_rnn_dim)\n",
        "        self.other_norm = nn.LayerNorm(other_rnn_dim)\n",
        "        self.other_gru = nn.GRU(other_rnn_dim, other_rnn_dim,\n",
        "                                batch_first=True, num_layers=2, dropout=0.1)\n",
        "\n",
        "        # Improved social attention\n",
        "        self.social_attn = ImprovedSocialAttention(\n",
        "            ego_dim=hidden_dim, other_dim=other_rnn_dim,\n",
        "            radius=radius, heads=social_heads\n",
        "        )\n",
        "\n",
        "        # Enhanced fusion network\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + other_rnn_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Separate heads for x and y coefficients\n",
        "        self.fc_x = nn.Linear(hidden_dim, degree + 1)\n",
        "        self.fc_y = nn.Linear(hidden_dim, degree + 1)\n",
        "\n",
        "    def enhanced_featurize(self, raw):\n",
        "        \"\"\"Enhanced feature engineering\"\"\"\n",
        "        xp, yp, vx, vy, hd = (raw[..., i] for i in range(5))\n",
        "\n",
        "        # Enhanced features\n",
        "        cos_h = torch.cos(hd)\n",
        "        sin_h = torch.sin(hd)\n",
        "        speed = torch.sqrt(vx**2 + vy**2 + 1e-6)\n",
        "        ax = torch.cat([torch.zeros_like(vx[..., :1]), vx[..., 1:] - vx[..., :-1]], dim=-1)\n",
        "        ay = torch.cat([torch.zeros_like(vy[..., :1]), vy[..., 1:] - vy[..., :-1]], dim=-1)\n",
        "\n",
        "        # Angular velocity\n",
        "        hd_diff = hd[..., 1:] - hd[..., :-1]\n",
        "        hd_diff = torch.where(hd_diff > torch.pi, hd_diff - 2*torch.pi, hd_diff)\n",
        "        hd_diff = torch.where(hd_diff < -torch.pi, hd_diff + 2*torch.pi, hd_diff)\n",
        "        angular_vel = torch.cat([torch.zeros_like(hd[..., :1]), hd_diff], dim=-1)\n",
        "\n",
        "        return torch.stack([xp, yp, vx, vy, cos_h, sin_h, speed, ax, ay], dim=-1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x.reshape(-1, 50, 50, 6)\n",
        "        ego_raw = x[:, 0]\n",
        "        others_raw = x[:, 1:]\n",
        "        B, A1, T, _ = others_raw.shape\n",
        "\n",
        "        # Enhanced feature engineering\n",
        "        ego_feat = self.enhanced_featurize(ego_raw)         \n",
        "        others_feat = self.enhanced_featurize(\n",
        "            others_raw.reshape(B*A1, T, 6)\n",
        "        ).reshape(B, A1, T, -1)                         \n",
        "\n",
        "        # Encode ego with bidirectional LSTM\n",
        "        ego_emb = self.norm(self.emb(ego_feat))\n",
        "        ego_out, (ego_h, _) = self.ego_lstm(ego_emb)\n",
        "\n",
        "        # Use final hidden state from both directions\n",
        "        ego_h = self.ego_proj(ego_h[-2:].transpose(0, 1).flatten(1))\n",
        "\n",
        "        # Enhanced other-agent encoding\n",
        "        other_emb = self.other_norm(self.other_emb(others_feat.view(B*A1, T, -1)))\n",
        "        _, other_h = self.other_gru(other_emb)\n",
        "        other_h = other_h[-1].view(B, A1, -1)\n",
        "\n",
        "        # Enhanced relative features\n",
        "        ego_last = ego_feat[:, -1, :2].unsqueeze(1)         \n",
        "        other_last = others_feat[:, :, -1, :2]              \n",
        "        rel_pos_vec = other_last - ego_last                 \n",
        "        dist = torch.norm(rel_pos_vec, dim=-1, keepdim=True)\n",
        "        rel_pos = torch.cat([rel_pos_vec, dist], dim=-1)   \n",
        "\n",
        "        # Relative velocity\n",
        "        ego_vel = ego_feat[:, -1, 2:4].unsqueeze(1)        \n",
        "        other_vel = others_feat[:, :, -1, 2:4]              \n",
        "        rel_vel = other_vel - ego_vel                       \n",
        "\n",
        "        # Social attention with relative velocity\n",
        "        social_ctx = self.social_attn(ego_h, other_h, rel_pos, rel_vel)\n",
        "\n",
        "        # Enhanced fusion\n",
        "        fused = self.fuse(torch.cat([ego_h, social_ctx], dim=-1))\n",
        "\n",
        "        # Separate prediction heads\n",
        "        a_coeffs = self.fc_x(fused)  # x coefficients\n",
        "        b_coeffs = self.fc_y(fused)  # y coefficients\n",
        "\n",
        "        t = torch.linspace(0, 1, 60, device=x.device)\n",
        "\n",
        "        basis_funcs = []\n",
        "        for i in range(self.degree + 1):\n",
        "            if i == 0:\n",
        "                basis_funcs.append(torch.ones_like(t))\n",
        "            elif i == 1:\n",
        "                basis_funcs.append(t)\n",
        "            else:\n",
        "                # Legendre polynomial recurrence\n",
        "                basis_funcs.append(((2*i-1) * t * basis_funcs[-1] - (i-1) * basis_funcs[-2]) / i)\n",
        "\n",
        "        t_poly = torch.stack(basis_funcs, -1)              \n",
        "        t_poly = t_poly.expand(B, -1, -1)               \n",
        "\n",
        "        # Generate predictions\n",
        "        x_pred = torch.bmm(t_poly, a_coeffs.unsqueeze(-1)).squeeze(-1)\n",
        "        y_pred = torch.bmm(t_poly, b_coeffs.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Add residual connection from last position\n",
        "        last_pos = ego_feat[:, -1, :2]\n",
        "        x_pred += last_pos[:, 0].unsqueeze(-1)\n",
        "        y_pred += last_pos[:, 1].unsqueeze(-1)\n",
        "\n",
        "        return torch.stack([x_pred, y_pred], dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPzJqeHU8B8U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EgoOnlyLSTMParametricTrajectoryFeatures(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=9,\n",
        "                 emb_dim=128,\n",
        "                 hidden_dim=256,\n",
        "                 lstm_layers=2,\n",
        "                 degree=3):\n",
        "        super().__init__()\n",
        "        self.degree = degree\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Embedding and normalization\n",
        "        self.emb = nn.Linear(input_dim, emb_dim)\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Bidirectional LSTM for ego features\n",
        "        self.ego_lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim,\n",
        "            batch_first=True, num_layers=lstm_layers,\n",
        "            bidirectional=True, dropout=0.1\n",
        "        )\n",
        "\n",
        "        # Project bi-LSTM output\n",
        "        self.ego_proj = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        # Deep feedforward network (analogous to fusion)\n",
        "        self.deep_block = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Separate heads for x and y coefficients\n",
        "        self.fc_x = nn.Linear(hidden_dim, degree + 1)\n",
        "        self.fc_y = nn.Linear(hidden_dim, degree + 1)\n",
        "\n",
        "    def enhanced_featurize(self, raw):\n",
        "        xp, yp, vx, vy, hd = (raw[..., i] for i in range(5))\n",
        "\n",
        "        cos_h = torch.cos(hd)\n",
        "        sin_h = torch.sin(hd)\n",
        "        speed = torch.sqrt(vx**2 + vy**2 + 1e-6)\n",
        "\n",
        "        ax = torch.cat([torch.zeros_like(vx[..., :1]), vx[..., 1:] - vx[..., :-1]], dim=-1)\n",
        "        ay = torch.cat([torch.zeros_like(vy[..., :1]), vy[..., 1:] - vy[..., :-1]], dim=-1)\n",
        "\n",
        "        hd_diff = hd[..., 1:] - hd[..., :-1]\n",
        "        hd_diff = torch.where(hd_diff > torch.pi, hd_diff - 2*torch.pi, hd_diff)\n",
        "        hd_diff = torch.where(hd_diff < -torch.pi, hd_diff + 2*torch.pi, hd_diff)\n",
        "        angular_vel = torch.cat([torch.zeros_like(hd[..., :1]), hd_diff], dim=-1)\n",
        "\n",
        "        return torch.stack([xp, yp, vx, vy, cos_h, sin_h, speed, ax, ay], dim=-1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x.reshape(-1, 50, 50, 6)\n",
        "        ego_raw = x[:, 0]\n",
        "\n",
        "        # Feature engineering\n",
        "        ego_feat = self.enhanced_featurize(ego_raw)\n",
        "\n",
        "        # Embedding and normalization\n",
        "        ego_emb = self.norm(self.emb(ego_feat))\n",
        "\n",
        "        # Encode with bi-LSTM\n",
        "        ego_out, (ego_h, _) = self.ego_lstm(ego_emb)\n",
        "\n",
        "        # Concatenate final hidden states\n",
        "        ego_h = self.ego_proj(ego_h[-2:].transpose(0, 1).flatten(1))\n",
        "\n",
        "        # Deep block\n",
        "        deep_out = self.deep_block(ego_h)\n",
        "\n",
        "        # Coefficient prediction\n",
        "        a_coeffs = self.fc_x(deep_out)\n",
        "        b_coeffs = self.fc_y(deep_out)\n",
        "\n",
        "        # Generate polynomial basis (Legendre)\n",
        "        t = torch.linspace(0, 1, 60, device=x.device)\n",
        "        basis_funcs = []\n",
        "        for i in range(self.degree + 1):\n",
        "            if i == 0:\n",
        "                basis_funcs.append(torch.ones_like(t))\n",
        "            elif i == 1:\n",
        "                basis_funcs.append(t)\n",
        "            else:\n",
        "                basis_funcs.append(((2*i-1)*t*basis_funcs[-1] - (i-1)*basis_funcs[-2])/i)\n",
        "        t_poly = torch.stack(basis_funcs, -1).expand(ego_h.shape[0], -1, -1)\n",
        "\n",
        "        # Generate predictions\n",
        "        x_pred = torch.bmm(t_poly, a_coeffs.unsqueeze(-1)).squeeze(-1)\n",
        "        y_pred = torch.bmm(t_poly, b_coeffs.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        return torch.stack([x_pred, y_pred], dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqHZmUFlQ7X0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedSocialAttention(nn.Module):\n",
        "    def __init__(self, ego_dim, other_dim, radius=40.0, heads=8):\n",
        "        super().__init__()\n",
        "        self.radius = radius\n",
        "        self.heads = heads\n",
        "        self.head_dim = other_dim // heads\n",
        "\n",
        "        # Multi-head projections\n",
        "        self.q_proj = nn.Linear(ego_dim, other_dim)\n",
        "        self.k_proj = nn.Linear(other_dim + 5, other_dim)\n",
        "        self.v_proj = nn.Linear(other_dim + 5, other_dim)\n",
        "        self.out = nn.Linear(other_dim, other_dim)\n",
        "\n",
        "        # Learnable positional encoding for relative positions\n",
        "        self.pos_encoding = nn.Sequential(\n",
        "            nn.Linear(5, other_dim // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(other_dim // 4, other_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, ego_h, other_h, rel_pos, rel_vel):\n",
        "        \"\"\"\n",
        "        ego_h   : [B, emb]             (query from ego LSTM)\n",
        "        other_h : [B, A-1, emb]        (other-agent encodings)\n",
        "        rel_pos : [B, A-1, 3]          (dx, dy, dist)\n",
        "        rel_vel : [B, A-1, 2]          (dvx, dvy)\n",
        "        \"\"\"\n",
        "        B, N, _ = other_h.shape\n",
        "\n",
        "        distances = rel_pos[..., 2]\n",
        "        mask = distances <= self.radius\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            return torch.zeros_like(other_h[:, 0])\n",
        "\n",
        "        # Combine relative position and velocity\n",
        "        rel_features = torch.cat([rel_pos, rel_vel], dim=-1)\n",
        "\n",
        "        # Enhanced K, V with positional encoding\n",
        "        pos_enc = self.pos_encoding(rel_features)\n",
        "        kv_input = other_h + pos_enc\n",
        "\n",
        "        q = self.q_proj(ego_h).view(B, 1, self.heads, self.head_dim)\n",
        "        k = self.k_proj(torch.cat([kv_input, rel_features], dim=-1)).view(B, N, self.heads, self.head_dim)\n",
        "        v = self.v_proj(torch.cat([kv_input, rel_features], dim=-1)).view(B, N, self.heads, self.head_dim)\n",
        "\n",
        "        # Scaled dot-product attention with improved masking\n",
        "        attn = torch.einsum('bqhd,bnhd->bnhq', q, k) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # Distance-aware attention weighting\n",
        "        distance_weight = torch.exp(-distances / (self.radius / 3)).unsqueeze(-1).unsqueeze(-1)\n",
        "        attn = attn * distance_weight\n",
        "\n",
        "        attn = attn.masked_fill(~mask.unsqueeze(-1).unsqueeze(-1), -1e9)\n",
        "        attn = F.softmax(attn, dim=1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        ctx = torch.einsum('bnhq,bnhd->bqhd', attn, v).flatten(2)\n",
        "        return self.out(ctx.squeeze(1))\n",
        "\n",
        "class NoPolynomialLSTMParametricTrajectoryFeatures(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=9,\n",
        "                 emb_dim=128,\n",
        "                 hidden_dim=256,\n",
        "                 lstm_layers=2,\n",
        "                 degree=3,\n",
        "                 social_heads=8,\n",
        "                 radius=35.0,\n",
        "                 other_rnn_dim=256):\n",
        "        super().__init__()\n",
        "        self.degree = degree\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.emb = nn.Linear(input_dim, emb_dim)\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.ego_lstm = nn.LSTM(emb_dim, hidden_dim,\n",
        "                                batch_first=True, num_layers=lstm_layers,\n",
        "                                bidirectional=True, dropout=0.1)\n",
        "\n",
        "        # Project bidirectional output back to hidden_dim\n",
        "        self.ego_proj = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        # Enhanced other-agent encoder\n",
        "        self.other_emb = nn.Linear(input_dim, other_rnn_dim)\n",
        "        self.other_norm = nn.LayerNorm(other_rnn_dim)\n",
        "        self.other_gru = nn.GRU(other_rnn_dim, other_rnn_dim,\n",
        "                                batch_first=True, num_layers=2, dropout=0.1)\n",
        "\n",
        "        # Improved social attention\n",
        "        self.social_attn = ImprovedSocialAttention(\n",
        "            ego_dim=hidden_dim, other_dim=other_rnn_dim,\n",
        "            radius=radius, heads=social_heads\n",
        "        )\n",
        "\n",
        "        # Enhanced fusion network\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + other_rnn_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # Direct output layer for x and y coordinates\n",
        "        self.output_fc = nn.Linear(hidden_dim, 60*2)\n",
        "\n",
        "    def enhanced_featurize(self, raw):\n",
        "        \"\"\"Enhanced feature engineering\"\"\"\n",
        "        xp, yp, vx, vy, hd = (raw[..., i] for i in range(5))\n",
        "\n",
        "        # Enhanced features\n",
        "        cos_h = torch.cos(hd)\n",
        "        sin_h = torch.sin(hd)\n",
        "        speed = torch.sqrt(vx**2 + vy**2 + 1e-6)\n",
        "        ax = torch.cat([torch.zeros_like(vx[..., :1]), vx[..., 1:] - vx[..., :-1]], dim=-1)\n",
        "        ay = torch.cat([torch.zeros_like(vy[..., :1]), vy[..., 1:] - vy[..., :-1]], dim=-1)\n",
        "\n",
        "        # Angular velocity\n",
        "        hd_diff = hd[..., 1:] - hd[..., :-1]\n",
        "        hd_diff = torch.where(hd_diff > torch.pi, hd_diff - 2*torch.pi, hd_diff)\n",
        "        hd_diff = torch.where(hd_diff < -torch.pi, hd_diff + 2*torch.pi, hd_diff)\n",
        "        angular_vel = torch.cat([torch.zeros_like(hd[..., :1]), hd_diff], dim=-1)\n",
        "\n",
        "        return torch.stack([xp, yp, vx, vy, cos_h, sin_h, speed, ax, ay], dim=-1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x.reshape(-1, 50, 50, 6)\n",
        "        ego_raw = x[:, 0]                    \n",
        "        others_raw = x[:, 1:]               \n",
        "        B, A1, T, _ = others_raw.shape\n",
        "\n",
        "        ego_feat = self.enhanced_featurize(ego_raw)         \n",
        "        others_feat = self.enhanced_featurize(\n",
        "            others_raw.reshape(B*A1, T, 6)\n",
        "        ).reshape(B, A1, T, -1)                           \n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        ego_emb = self.norm(self.emb(ego_feat))\n",
        "        ego_out, (ego_h, _) = self.ego_lstm(ego_emb)\n",
        "\n",
        "        # Use final hidden state from both directions\n",
        "        ego_h = self.ego_proj(ego_h[-2:].transpose(0, 1).flatten(1))\n",
        "\n",
        "        # Enhanced other-agent encoding\n",
        "        other_emb = self.other_norm(self.other_emb(others_feat.view(B*A1, T, -1)))\n",
        "        _, other_h = self.other_gru(other_emb)\n",
        "        other_h = other_h[-1].view(B, A1, -1)             \n",
        "\n",
        "        # Enhanced relative features\n",
        "        ego_last = ego_feat[:, -1, :2].unsqueeze(1)        \n",
        "        other_last = others_feat[:, :, -1, :2]          \n",
        "        rel_pos_vec = other_last - ego_last               \n",
        "        dist = torch.norm(rel_pos_vec, dim=-1, keepdim=True)\n",
        "        rel_pos = torch.cat([rel_pos_vec, dist], dim=-1)\n",
        "\n",
        "        # Relative velocity\n",
        "        ego_vel = ego_feat[:, -1, 2:4].unsqueeze(1)\n",
        "        other_vel = others_feat[:, :, -1, 2:4]\n",
        "        rel_vel = other_vel - ego_vel\n",
        "\n",
        "        # Social attention with relative velocity\n",
        "        social_ctx = self.social_attn(ego_h, other_h, rel_pos, rel_vel)\n",
        "\n",
        "        # Enhanced fusion\n",
        "        fused = self.fuse(torch.cat([ego_h, social_ctx], dim=-1))\n",
        "\n",
        "        # Direct output layer\n",
        "        output = self.output_fc(fused)\n",
        "        return output.view(-1, 60, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN86fLYgPOlQ"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_features, output_features):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Define the layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(256, output_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        x = x.reshape(-1, 50, 50, 6)\n",
        "        x = x[:, 0, :, :]\n",
        "        x = self.flatten(x)\n",
        "        x = self.mlp(x)\n",
        "        return x.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9QawQriTLWw"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dim=256, output_dim=60 * 2):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=2)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        x= x.reshape(-1, 50, 50, 6)\n",
        "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
        "\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApchN3DAPRuT"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_dim=6, emb_dim=128, nhead=8, num_layers=6, output_dim=60 * 2):\n",
        "        super().__init__()\n",
        "        self.input_fc = nn.Linear(input_dim, emb_dim)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=emb_dim,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=256,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_fc = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        x = x.reshape(-1, 50, 50, 6)\n",
        "        x = x[:, 0, :, :]\n",
        "\n",
        "        emb = self.input_fc(x)\n",
        "        enc_out = self.encoder(emb)\n",
        "        final_hidden = enc_out[:, -1, :]\n",
        "\n",
        "        out = self.output_fc(final_hidden)\n",
        "        return out.view(-1, 60, 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SPd9wIpjKmz"
      },
      "source": [
        "#### Your Optimizer and Hyperparameters for Question 2 Problem A (Try to use different optimizers and hyperparameters for your model and see how it affects the performance of your model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3BGiHJ8wwAF"
      },
      "outputs": [],
      "source": [
        "class TrajectoryLoss(nn.Module):\n",
        "    def __init__(self, loss_type='weighted', weight_scheme='linear', **kwargs):\n",
        "        super().__init__()\n",
        "        self.loss_type = loss_type\n",
        "        self.weight_scheme = weight_scheme\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        if self.loss_type == 'standard':\n",
        "            return nn.MSELoss()(pred, target)\n",
        "\n",
        "        elif self.loss_type == 'weighted':\n",
        "            if self.weight_scheme == 'linear':\n",
        "                start_weight = self.kwargs.get('start_weight', 1.0)\n",
        "                end_weight = self.kwargs.get('end_weight', 2.0)\n",
        "                weights = torch.linspace(start_weight, end_weight, 60, device=pred.device)\n",
        "\n",
        "            elif self.weight_scheme == 'quadratic':\n",
        "                start_weight = self.kwargs.get('start_weight', 1.0)\n",
        "                end_weight = self.kwargs.get('end_weight', 2.0)\n",
        "                t = torch.linspace(0, 1, 60, device=pred.device)\n",
        "                weights = start_weight + (end_weight - start_weight) * t ** 2\n",
        "\n",
        "            elif self.weight_scheme == 'exponential':\n",
        "                start_weight = self.kwargs.get('start_weight', 1.0)\n",
        "                end_weight = self.kwargs.get('end_weight', 2.0)\n",
        "                t = torch.linspace(0, 1, 60, device=pred.device)\n",
        "                weights = start_weight * (end_weight / start_weight) ** t\n",
        "\n",
        "            weights = weights.view(1, -1, 1)\n",
        "            return ((pred - target) ** 2 * weights).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGlM0tnkjKmz"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "\n",
        "model = ImprovedLSTMParametricTrajectoryFeatures(degree=3, lstm_layers=2, other_rnn_dim=256).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "#scheduler = CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
        "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "early_stopping_patience = 12\n",
        "best_val_loss = float('inf')\n",
        "no_improvement = 0\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = TrajectoryLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjlFPE2jKm0"
      },
      "source": [
        "#### Using the Simple Linear Regression Model for Question 2B and Visualize the validation loss(MAE) (Hint: You should adapt the code for training loss and try to draw graphs as specified in the project description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B8H3sUJemxqz",
        "outputId": "b9a13071-5e56-4677-9e71-369974a06a91"
      },
      "outputs": [],
      "source": [
        "# Initialize model tracking variables\n",
        "best_models = {\n",
        "    'first': {'loss': float('inf'), 'path': 'best_model_1st.pt'},\n",
        "    'second': {'loss': float('inf'), 'path': 'best_model_2nd.pt'},\n",
        "    'third': {'loss': float('inf'), 'path': 'best_model_3rd.pt'}\n",
        "}\n",
        "\n",
        "def update_best_models(current_loss, model_state_dict):\n",
        "    \"\"\"\n",
        "    Update the top 3 models if current model beats the best model.\n",
        "    Only stores a new model if it beats the current best (first place).\n",
        "    \"\"\"\n",
        "    if current_loss < best_models['first']['loss'] - 1e-4:\n",
        "        old_first_state = None\n",
        "        if best_models['first']['loss'] != float('inf'):\n",
        "            old_first_state = torch.load(best_models['first']['path'])\n",
        "\n",
        "        old_second_state = None\n",
        "        if best_models['second']['loss'] != float('inf'):\n",
        "            old_second_state = torch.load(best_models['second']['path'])\n",
        "\n",
        "        if old_second_state is not None:\n",
        "            torch.save(old_second_state, best_models['third']['path'])\n",
        "            best_models['third']['loss'] = best_models['second']['loss']\n",
        "\n",
        "        if old_first_state is not None:\n",
        "            torch.save(old_first_state, best_models['second']['path'])\n",
        "            best_models['second']['loss'] = best_models['first']['loss']\n",
        "\n",
        "        torch.save(model_state_dict, best_models['first']['path'])\n",
        "        best_models['first']['loss'] = current_loss\n",
        "\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "# Training loop\n",
        "no_improvement = 0\n",
        "early_stopping_patience = 12\n",
        "\n",
        "for epoch in tqdm.tqdm(range(110), desc=\"Epoch\", unit=\"epoch\"):\n",
        "    # ---- Training ----\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch)\n",
        "        y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "        loss = criterion(pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # ---- Validation ----\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_mae = 0\n",
        "    val_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            val_loss += criterion(pred, y).item()\n",
        "\n",
        "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            val_mae += nn.L1Loss()(pred, y).item()\n",
        "            val_mse += nn.MSELoss()(pred, y).item()\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    val_loss /= len(val_dataloader)\n",
        "    val_mae /= len(val_dataloader)\n",
        "    val_mse /= len(val_dataloader)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    tqdm.tqdm.write(f\"Epoch {epoch:03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
        "\n",
        "    # Update best models - only stores if it beats the current best\n",
        "    model_stored = update_best_models(val_loss, model.state_dict())\n",
        "\n",
        "    if model_stored:\n",
        "        no_improvement = 0\n",
        "        tqdm.tqdm.write(f\"New best model saved! Current ranking losses: 1st: {best_models['first']['loss']:.6f}, 2nd: {best_models['second']['loss']:.6f}, 3rd: {best_models['third']['loss']:.6f}\")\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "        if no_improvement >= early_stopping_patience:\n",
        "            print(\"Early stop!\")\n",
        "            break\n",
        "\n",
        "print(\"\\nFinal model rankings:\")\n",
        "print(f\"1st place (best): {best_models['first']['loss']:.6f} - {best_models['first']['path']}\")\n",
        "print(f\"2nd place: {best_models['second']['loss']:.6f} - {best_models['second']['path']}\")\n",
        "print(f\"3rd place: {best_models['third']['loss']:.6f} - {best_models['third']['path']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0J6y9GYjKm0"
      },
      "source": [
        "#### Randomly sample validation dataset and Visualize the ground truth and your predictions on a 2D plane for Question 3 Problem A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR9CWM0rTle1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_trajectory(ax, pred, gt, title=None):\n",
        "    ax.cla()\n",
        "    # Plot the predicted future trajectory\n",
        "    ax.plot(pred[0,:60,0], pred[0,:60,1], color='red', label='Predicted Future Trajectory')\n",
        "\n",
        "    # Plot the ground truth future trajectory\n",
        "    ax.plot(gt[0,:60,0], gt[0,:60,1], color='blue', label='Ground Truth Future Trajectory')\n",
        "\n",
        "    # Optionally set axis limits, labels, and title.\n",
        "    x_max = max(pred[..., 0].max(), gt[..., 0].max())\n",
        "    x_min = min(pred[..., 0].min(), gt[..., 0].min())\n",
        "    y_max = max(pred[..., 1].max(), gt[..., 1].max())\n",
        "    y_min = min(pred[..., 1].min(), gt[..., 1].min())\n",
        "\n",
        "    ax.set_xlim(x_min, x_max)\n",
        "    ax.set_ylim(y_min, y_max)\n",
        "    ax.set_xlabel('X-axis')\n",
        "    ax.set_ylabel('Y-axis')\n",
        "\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "LTxijO3fTmR_",
        "outputId": "d007c923-48ed-4649-a69a-b70f4d5b4827"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(best_models['first']['path']))\n",
        "model.eval()\n",
        "\n",
        "#idx = random.choice(range(len(val_dataset)))\n",
        "idx = 276\n",
        "batch = val_dataset[idx]\n",
        "batch = batch.to(device)\n",
        "\n",
        "pred = model(batch)\n",
        "gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0)\n",
        "pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "gt = gt * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "pred = pred.detach().cpu().numpy()\n",
        "gt = gt.detach().cpu().numpy()\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "plot_trajectory(ax, pred, gt, title=f\"Sample {idx}, Proposed Model\")\n",
        "plt.tight_layout()\n",
        "save_path = \"trajectory_plot_imp.png\"\n",
        "plt.savefig(save_path)\n",
        "plt.show()\n",
        "\n",
        "# Download\n",
        "files.download(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "9f46T61f83GM",
        "outputId": "66438bf5-591b-4959-ef82-d5c84c5c90d6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "from google.colab import files\n",
        "\n",
        "plt.plot(range(1, len(zero_heading_val) + 1), zero_heading_val, label='Degree 3')\n",
        "plt.plot(range(1, len(degree_5_val) + 1), degree_5_val, label='Degree 5')\n",
        "plt.plot(range(1, len(degree_7_val) + 1), degree_7_val, label='Degree 7')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('validation_loss_degree.png')\n",
        "plt.show()\n",
        "\n",
        "files.download('validation_loss_degree.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "sAKyvu_beyvX",
        "outputId": "8af209c7-6787-4471-d609-5d80e2d175d6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "from google.colab import files\n",
        "\n",
        "plt.plot(range(1, len(zero_heading_train) + 1), zero_heading_train, label='Degree 3')\n",
        "plt.plot(range(1, len(degree_5_train) + 1), degree_5_train, label='Degree 5')\n",
        "plt.plot(range(1, len(degree_7_train) + 1), degree_7_train, label='Degree 7')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('training_loss_degree.png')\n",
        "plt.show()\n",
        "\n",
        "files.download('training_loss_degree.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBzzm9w9jKm0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_trajectory(ax, pred, gt, title=None):\n",
        "    ax.cla()\n",
        "    # Plot the predicted future trajectory\n",
        "    ax.plot(pred[0,:60,0], pred[0,:60,1], color='red', label='Predicted Future Trajectory')\n",
        "\n",
        "    # Plot the ground truth future trajectory\n",
        "    ax.plot(gt[0,:60,0], gt[0,:60,1], color='blue', label='Ground Truth Future Trajectory')\n",
        "\n",
        "    # Optionally set axis limits, labels, and title.\n",
        "    x_max = max(pred[..., 0].max(), gt[..., 0].max())\n",
        "    x_min = min(pred[..., 0].min(), gt[..., 0].min())\n",
        "    y_max = max(pred[..., 1].max(), gt[..., 1].max())\n",
        "    y_min = min(pred[..., 1].min(), gt[..., 1].min())\n",
        "\n",
        "    ax.set_xlim(x_min, x_max)\n",
        "    ax.set_ylim(y_min, y_max)\n",
        "    ax.set_xlabel('X-axis')\n",
        "    ax.set_ylabel('Y-axis')\n",
        "\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw5fyegA2GN1",
        "outputId": "bfadc3e0-fc0f-4bd6-ed69-361c22e5a064"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(best_models['first']['path']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "CnKNooRAjKm0",
        "outputId": "77308358-d461-425b-baec-46ff28b8c335"
      },
      "outputs": [],
      "source": [
        "#model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# randomly select 4 samples from the validation set\n",
        "random_indices = random.sample(range(len(val_dataset)), 4)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
        "axes = axes.flatten()  # Flatten the array to iterate single axes objects\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    batch = val_dataset[idx]\n",
        "    batch = batch.to(device)\n",
        "    pred = model(batch)\n",
        "    gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0)\n",
        "\n",
        "    pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "    gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0) * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "\n",
        "    pred = pred.detach().cpu().numpy()\n",
        "    gt = gt.detach().cpu().numpy()\n",
        "\n",
        "    # Plot the trajectory using the i-th axis\n",
        "    plot_trajectory(axes[i], pred, gt, title=f\"Sample {idx}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccytp4y_jKm1"
      },
      "source": [
        "#### Output your predictions of the best model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01cBZ4WvjKm1"
      },
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "#best_model = torch.load(\"best_model.pt\")\n",
        "#model = LinearRegressionModel().to(device)\n",
        "# model = MLP(50 * 50 * 6, 60 * 2).to(device)\n",
        "# model = LSTM().to(device)\n",
        "#model = Agent0HybridTransformer(emb_dim=256,num_layers=6).to(device)\n",
        "#model = Agent0TemporalAttentionTransformer(emb_dim=256, num_layers=6).to(device)\n",
        "#model = Agent0TemporalAttentionTransformer(emb_dim=256, num_layers=8).to(device)\n",
        "\n",
        "# Old best (second best submission):\n",
        "#model = ImprovedLSTMParametricTrajectoryFeatures(degree=3, lstm_layers=2).to(device)\n",
        "\n",
        "# Best so far:\n",
        "#model = ImprovedLSTMParametricTrajectoryFeatures(degree=3, lstm_layers=2, other_rnn_dim=256).to(device)\n",
        "\n",
        "\n",
        "model = ImprovedLSTMParametricTrajectoryFeatures(degree=3, lstm_layers=2, other_rnn_dim=256).to(device)\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(best_models['first']['path']))\n",
        "#model.load_state_dict(best_model)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "\n",
        "        data_list = batch.to_data_list()\n",
        "\n",
        "        batch_predictions = []\n",
        "        for i, data in enumerate(data_list):\n",
        "            # Get the prediction for this sample\n",
        "            single_pred_norm = pred_norm[i]\n",
        "\n",
        "            # Unnormalize (scale back up)\n",
        "            single_pred = single_pred_norm * data.scale\n",
        "\n",
        "            # Translate back from origin (add back the translation)\n",
        "            single_pred = single_pred + data.origin\n",
        "\n",
        "            # Rotate back to world coordinates\n",
        "            R = data.rotation\n",
        "            single_pred = single_pred @ R\n",
        "\n",
        "            batch_predictions.append(single_pred.cpu().numpy())\n",
        "\n",
        "        # Stack predictions for this batch\n",
        "        batch_pred_array = np.stack(batch_predictions, axis=0)\n",
        "        pred_list.append(batch_pred_array)\n",
        "\n",
        "# Concatenate all predictions\n",
        "pred_list = np.concatenate(pred_list, axis=0)\n",
        "\n",
        "# Reshape for submission format\n",
        "pred_output = pred_list.reshape(-1, 2)\n",
        "\n",
        "# Create submission DataFrame\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBxOkrGg8oVr",
        "outputId": "e3c8733f-10df-45f7-fd38-745b62d082c5"
      },
      "outputs": [],
      "source": [
        "print(output_df.head(12))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TZ7unH-Y54dC",
        "outputId": "d66ead3d-42b7-4f93-a707-f102812f240a"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCnzydRfjKm1"
      },
      "source": [
        "## Step 4: Summarize your experiments and results in table and figures in the submitted PDF file for Question 3 Problem A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIL-7RGWjKm1"
      },
      "source": [
        "## Step 5: Analyze the results, identify the issues and plan for the improvement in the submitted PDF file for Question 3 Problem B"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
